{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning Project\n",
    "## Articles Analysis with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisando a proposta\n",
    "\n",
    "#### Background:\n",
    "\n",
    "Todos os dias pesquisadores, estudantes de graduação, mestrado, doutorado, curiosos estão descobrindo e escrevendo sobre nossa visão do mundo, artigos sobre astronomia, psicologia, informática, engenharia mecânica, entre outros, questionam e encontram informações sobre pequenas, grandes, estranhas, importantes ou inúteis descobertas. Se separarmos uma certa área específica, será que uma pessoa é capaz de ler, entender, conversar com os autores daquele assunto? Num mundo tão grande, com uma produção tão vasta, é difícil.\n",
    "\n",
    "Em 2011, por exemplo, os pesquisadores brasileiros publicaram 49.664 artigos 2, olhando o mapa acima, talvez no mesmo ano, os Estados Unidos tenham publicado cerca de 20 vezes mais. Mas a disputa aqui não é sobre quem publica mais, mas sim, sobre seria possível consumir uma quantidade grande de produção científica.\n",
    "\n",
    "O trabalho acadêmico tem por critério de qualidade, geralmente, a originalidade do trabalho, os pesquisadores citam em seus projetos descobertas originais, ou aplicação de métodos em novos tipos de dados, entre outras maneiras, porém de alguma forma estes pesquisadores estão ligados, por seus assuntos ou por métodos utilizados, o mundo científico também adotou a interdisciplinaridade, por vezes alguns artigos de medicina irão usar técnicas de ciências da computação ou matemática para comprovar uma descoberta, a arte pode usar a física, a física pode usar a psicologia.\n",
    "\n",
    "Então se alguém escreve, ou se vai escrever sobre um assunto, quem são as outras pessoas da área dela, ou não, que estão produzindo sobre assuntos que dividem características com as essas publicações, se uma universidade ou revista quiser saber quais autores tem mais similaridade nos métodos usados, ou nos dados pesquisados, como unir essa informação sem ter que ler toda a volumosa produção científica que o mundo produz?\n",
    "\n",
    "#### Problema e Justificativa:\n",
    "\n",
    "Analisar em que revistas este artigo tem mais probabilidade de sucesso de aceitação, sabendo quais grupos as revistas mais publicam. Este algoritmo poderia ser o mesmo utilizado para agrupar os dados, no entanto, para explorar mais ferramentas de aprendizado de máquina, será utilizado um algoritmo para classificação, utilizando como variável alvo o grupo encontrado na etapa de agrupamento. \n",
    "\n",
    "#### Solução Proposta:\n",
    "\n",
    "A solução e objetivos propostos são:\n",
    "Utilizar processamento de linguagem natural para ler resumos de artigos científicos e encontrar palavras importantes para classificar seus autores;\n",
    "Clusterizar os autores e revistas onde os artigos foram publicados para encontrar grupos naturalmente formados;\n",
    "Prever a possibilidade de um autor fazer parte de um grupo de autores ou de publicar em uma revista;\n",
    "\n",
    "(O autor propôs esta solução para utilizar aprendizagem supervisionada e não supervisionada no exercício final).\n",
    "\n",
    "#### Solução Proposta pelo Orientador:\n",
    "\n",
    "Criar um algortimo de aprendizagem supervisionada e já utilizar as revistas como variável alvo, sem a necessidade de realizar clusterização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciando o projeto\n",
    "\n",
    "Alguns pacotes foram criados para auxiliar a execução do projeto, os mesmos podem ser acessados no diretório do github, todas as classes e scripts criados possuem docstring para detalhar a utilização dos mesmos. O objetivo era deixar no notebook apenas as partes mais importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de dados e inputs\n",
    "\n",
    "Os artigos foram coletados, manualmente, no site (https://www.ncbi.nlm.nih.gov/pubmed/). No entanto, em vez de utilizar os artigos no formato .nbib, como ideaizado no projeto, será utilizado arquivos .xml.\n",
    "\n",
    "Eles estão no idioma inglês, para evitar erros de viés durante a elaboração dos algoritmos, todos os artigos deste website são sobre medicina, de modo que possamos reduzir o grupo de observação e não coletar dados extremamente distantes que não sejam efetivos no momento da construção do algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de artigos: 124\n",
      "Número de atributos: 491\n",
      "\n",
      "Basic & clinical pharmacology & toxicology 17\n",
      "Child psychiatry and human development 15\n",
      "Clinical psychology & psychotherapy 20\n",
      "Drug and alcohol dependence 17\n",
      "Journal of affective disorders 20\n",
      "Neuropharmacology 17\n",
      "Psychiatry investigation 18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "# Important nltk packages you might download to execute the codes\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from custom_entities.article import ArticleData\n",
    "from custom_helpers.pandas_helper import insert_article_to_pandas\n",
    "\n",
    "# Path of folder with all articles\n",
    "# path = 'C:/Users/Paulo/Documents/PyCharmProjects/papers_abstract_analysis/papers'\n",
    "path = 'C:/Users/Paulo Henrique/PycharmProjects/papers_abstract_analysis/papers'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.xml')):\n",
    "    root = xml.etree.ElementTree.parse(filename).getroot()\n",
    "    article = ArticleData(root)\n",
    "    df = insert_article_to_pandas(df, article)\n",
    "    \n",
    "df = df.fillna(0)\n",
    "\n",
    "n_articles = len(df.index)\n",
    "n_features = len(df.columns) - 1\n",
    "# Imprime os resultados\n",
    "print \"Número total de artigos: {}\".format(n_articles)\n",
    "print \"Número de atributos: {}\\n\".format(n_features)\n",
    "\n",
    "for index, row in (df.groupby(['.JOURNAL']).count()).iterrows():\n",
    "    print index, row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador com revista como variável alvo\n",
    "### Separação da variável alvo\n",
    "\n",
    "Inicialmente será criado um classificador usando as revistas como variváveis alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos (Primeiras 40):\n",
      "['abstin', 'access', 'accommod', 'acetaminophen', 'across', 'action', 'activ', 'addict', 'adolesc', 'adrenerg', 'adult', 'adulthood', 'affair', 'affect', 'agent', 'aggress', 'alcohol', 'alexithymia', 'allianc', 'almost', 'although', 'aluminium', 'amazon', 'ambival', 'among', 'analges', 'analysi', 'androstan', 'anesthet', 'anti-epilept', 'antibiot', 'antidepress', 'anxieti', 'anxiou', 'apach', 'aptam', 'arson', 'assert', 'assess', 'associ']\n",
      "\n",
      "Coluna-alvo: .JOURNAL\n"
     ]
    }
   ],
   "source": [
    "# Extrair coluna de atributos\n",
    "feature_cols = list(df.columns[1:])\n",
    "\n",
    "# Extrair coluna alvo\n",
    "target_col = df.columns[0] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos (Primeiras 40):\\n{}\".format(feature_cols[0:40])\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separação do data_set de atributos e alvo\n",
    "X_all = df[feature_cols]\n",
    "y_all = df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dos Dados de Treinamento e Teste\n",
    "\n",
    "Embaralhar aleatoriamente os dados (X_all, y_all) em subconjuntos de treinamento e teste.\n",
    "    > Utilizar 75% de dados em treinamento 25% em teste.\n",
    "    > Armazenar os resultados em X_train, X_test, y_train e y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 93 amostras.\n",
      "O conjunto de teste tem 31 amostras.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Importar divisor de amostra\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# 25% para teste\n",
    "num_test = 0.25\n",
    "custom_random_state = 32\n",
    "\n",
    "# Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=custom_random_state)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilidades para ajustar treinamento\n",
    "\n",
    "Implemtanção de métodos para auxiliar o treinamento e visão de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implemtação de codigo para imprimir o markdown sozinho :)\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "global col_1\n",
    "global col_2\n",
    "global col_3\n",
    "global col_4\n",
    "global col_5\n",
    "col_1 = 'Tamanho do Conj de Treinamento'\n",
    "col_2 = 'Tempo de Treinamento'\n",
    "col_3 = 'Tempo de Estimativa (teste)'\n",
    "col_4 = 'Pontuacao Accuracy (treinamento)'\n",
    "col_5 = 'Pontuacao Accuracy (teste)'\n",
    "\n",
    "global df_model\n",
    "df_model = pd.DataFrame(columns=[col_1, col_2, col_3, col_4, col_5])\n",
    "df_backup = df_model.copy()\n",
    "\n",
    "def pandas_df_to_markdown_table(df):\n",
    "    '''\n",
    "    Função para tabular com markdown.\n",
    "    Creditos para o autor na publicação abaixo.\n",
    "    Acessado em https://stackoverflow.com/questions/33181846/programmatically-convert-pandas-dataframe-to-markdown-table\n",
    "    '''\n",
    "    from IPython.display import Markdown, display\n",
    "    fmt = ['---' for i in range(len(df.columns))]\n",
    "    df_fmt = pd.DataFrame([fmt], columns=df.columns)\n",
    "    df_formatted = pd.concat([df_fmt, df])\n",
    "    display(Markdown(df_formatted.to_csv(sep=\"|\", index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train, index=None):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "    if index:\n",
    "        df_model.loc[index,col_2] = \"{:.4f} seg\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target, index=None):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    if index:\n",
    "        df_model.loc[index, col_3] = \"{:.4f} seg\".format(end - start)\n",
    "    \n",
    "    return accuracy_score(target.values, y_pred)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    index = len(X_train)\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, index)\n",
    "    df_model.loc[index, col_1] = index\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train, index)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    time_train = predict_labels(clf, X_train, y_train, index)\n",
    "    time_test = predict_labels(clf, X_test, y_test, index)\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(time_train)\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(time_test)\n",
    "    df_model.loc[index, col_4] = \"{:.4f}.\".format(time_train)\n",
    "    df_model.loc[index, col_5] = \"{:.4f}.\".format(time_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Desempenho do Modelo\n",
    "\n",
    "Implemtanção de métodos para auxiliar o treinamento e visão de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um LogisticRegression com 93 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0030 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9785.\n",
      "Pontuação F1 para o conjunto de teste: 0.4194.\n",
      "\n",
      "Treinando um DecisionTreeClassifier com 93 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9785.\n",
      "Pontuação F1 para o conjunto de teste: 0.4194.\n",
      "\n",
      "Treinando um SVC com 93 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0090 segundos\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "As previsões foram feitas em 0.0010 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.1828.\n",
      "Pontuação F1 para o conjunto de teste: 0.0968.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar três modelos de aprendizagem supervisionada do sklearn\n",
    "# from sklearn import model_A\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn import model_B\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from skearln import model_C\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = LogisticRegression(random_state=custom_random_state)\n",
    "clf_B = DecisionTreeClassifier(random_state=custom_random_state)\n",
    "clf_C = SVC(random_state=custom_random_state)\n",
    "\n",
    "# Cria array de classificadores e dataframe de resultados\n",
    "clfs = [clf_A, clf_B, clf_C]\n",
    "df_A = None\n",
    "df_B = None\n",
    "df_C = None\n",
    "dfs = [df_A, df_B, df_C]\n",
    "\n",
    "# Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "for i, x in enumerate(clfs):\n",
    "    train_predict(clfs[i], X_train, y_train, X_test, y_test)\n",
    "    print ''\n",
    "    dfs[i] = df_model.copy()\n",
    "    df_model = df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\n",
      "Classificador 1 - LogisticRegression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tamanho do Conj de Treinamento|Tempo de Treinamento|Tempo de Estimativa (teste)|Pontuacao Accuracy (treinamento)|Pontuacao Accuracy (teste)\n",
       "---|---|---|---|---\n",
       "93|0.0030 seg|0.0000 seg|0.9785.|0.4194.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\n",
      "Classificador 2 - DecisionTreeClassifier\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tamanho do Conj de Treinamento|Tempo de Treinamento|Tempo de Estimativa (teste)|Pontuacao Accuracy (treinamento)|Pontuacao Accuracy (teste)\n",
       "---|---|---|---|---\n",
       "93|0.0040 seg|0.0000 seg|0.9785.|0.4194.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\n",
      "Classificador 3 - SVC\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tamanho do Conj de Treinamento|Tempo de Treinamento|Tempo de Estimativa (teste)|Pontuacao Accuracy (treinamento)|Pontuacao Accuracy (teste)\n",
       "---|---|---|---|---\n",
       "93|0.0090 seg|0.0010 seg|0.1828.|0.0968.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exibindo tabelas automaticamente\n",
    "for i, x in enumerate(clfs):\n",
    "    print '\\033[1m' + '\\033[4m' + \"\\nClassificador \" + str(i+1) + ' - ' + clfs[i].__class__.__name__ + '\\033[0m'\n",
    "    pandas_df_to_markdown_table(dfs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrando o Melhor Modelo\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0010 segundos.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "\n",
      "O modelo calibrado tem Accuracy de 0.9462 no conjunto de treinamento.\n",
      "O modelo calibrado tem Accuracy de 0.5161 no conjunto de teste.\n",
      "\n",
      "Melhores parametros:\n",
      "C = 0.1\n",
      "class_weight = balanced\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "# Novo embaralhamento para busca de parametros\n",
    "X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_all, y_all, test_size=num_test, random_state=custom_random_state)\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "class_weight = ['balanced', None]\n",
    "parameters = {'C': C,\n",
    "              'class_weight': class_weight}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = LogisticRegression(random_state=custom_random_state)\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=f1_scorer, cv=5, verbose=0)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetros\n",
    "tuned_f1_train = \"{:.4f}\".format(predict_labels(clf, X_train, y_train))\n",
    "tuned_f1_test = \"{:.4f}\".format(predict_labels(clf, X_test, y_test))\n",
    "print \"\\nO modelo calibrado tem Accuracy de \" + tuned_f1_train + \" no conjunto de treinamento.\"\n",
    "print \"O modelo calibrado tem Accuracy de \" + tuned_f1_test + \" no conjunto de teste.\"\n",
    "\n",
    "print \"\\nMelhores parametros:\"\n",
    "print \"C = \" + str(grid_obj.best_params_['C'])\n",
    "print \"class_weight = \" + str(grid_obj.best_params_['class_weight'])\n",
    "\n",
    "df_tuned = dfs[0].copy()\n",
    "df_tuned.loc[:, col_4] = tuned_f1_train\n",
    "df_tuned.loc[:, col_5] = tuned_f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\n",
      "Antes: LogisticRegression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tamanho do Conj de Treinamento|Pontuacao Accuracy (treinamento)|Pontuacao Accuracy (teste)\n",
       "---|---|---\n",
       "93|0.9785.|0.4194.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\n",
      "Depois: LogisticRegression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Tamanho do Conj de Treinamento|Pontuacao Accuracy (treinamento)|Pontuacao Accuracy (teste)\n",
       "---|---|---\n",
       "93|0.9462|0.5161\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print '\\033[1m' + '\\033[4m' + \"\\nAntes: \" + clfs[0].__class__.__name__ + '\\033[0m'\n",
    "pandas_df_to_markdown_table(dfs[0].loc[:,[col_1, col_4, col_5]])\n",
    "\n",
    "print '\\033[1m' + '\\033[4m' + \"\\nDepois: \" + clfs[0].__class__.__name__ + '\\033[0m'\n",
    "pandas_df_to_markdown_table(df_tuned.loc[:,[col_1, col_4, col_5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
